{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c72fd2be",
   "metadata": {},
   "source": [
    "## Написать приложение или функцию, которые собирают основные новости с сайта на выбор lenta.ru, yandex-новости. Для парсинга использовать XPath.\n",
    "\n",
    "### Структура данных в виде словаря должна содержать:\n",
    "\n",
    "- *название источника;\n",
    "\n",
    "- наименование новости;\n",
    "\n",
    "- ссылку на новость;\n",
    "\n",
    "- дата публикации.\n",
    "\n",
    "Минимум один сайт, максимум - все два"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37fa380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "from lxml import html\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc9da04",
   "metadata": {},
   "source": [
    "# 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ea720",
   "metadata": {},
   "source": [
    "### https://yandex.ru/news\n",
    "\n",
    "В Московской области странице Яндекс-новостей 13 категорий: **'top-heading', 'Москва и область0', 'Интересное1', 'Политика2', 'Общество3', 'Экономика4', 'В мире5', 'Спорт6', 'Происшествия7', 'Культура8', 'Технологии9', 'Наука10', 'Авто11'**\n",
    "\n",
    "и 3 размера блоков новстей:\n",
    "\n",
    "- *блок 8* - самый большой\n",
    "- *блок 4*  - среднего размера\n",
    "- *блок 6* - самый маленький (это, по сути, размер болока 8 с четыремя новостями в нём, т.е. 6+6+6+6=8)\n",
    "\n",
    "на странице всего 65 блоков разного размера из разных категорий\n",
    "\n",
    "Написал функцию yandex_news_scraping(), которая собирает и сортирует новости по своим тематическим категориям, пронумеровывая новости в зависимости от их категории. Костяк структуры такой:\n",
    "\n",
    "$главный \\; первый \\; раздел$\n",
    "\n",
    "$\\;\\;$ -блок-8: general-новость top-heading\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ -блок-4: 1-я новость top-heading\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ -блок-4: 2-я новость top-heading\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ -блок-4: 3-я новость top-heading\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ -блок-4: 4-я новость top-heading\n",
    "\n",
    "$остальные\\;разделы$\n",
    "\n",
    "$\\;\\;\\;\\;$ -блок-4: general-новость\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ -блок-6: 1-я новость\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ -блок-6: 2-я новость\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ -блок-6: 3-я новость\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ -блок-6: 4-я новость\n",
    "\n",
    "каждая новость содержит ключи: \n",
    "\n",
    "- **eadlines** - заголовок\n",
    "\n",
    "- **text_news** - краткое описание\n",
    "\n",
    "- **link_to_news** - ссылка на новость\n",
    "\n",
    "- **news_source** - источник новости\n",
    "\n",
    "- **news_time** - время публикации новости\n",
    "\n",
    "В итоге мы получаем JSON-структуру данных, которую записываем в файл\n",
    "\n",
    "P.S: часть путей в xpath может показаться дублированной, но это не совсем так, т.к. отсчсёт пути идёт от названия категории, которое меняется в цикле + такой вид, на мой взгляд, уобен при незначительных изменениях вёрстки на сайте, так как, видя путь, его будет легче подогать под возможные изменения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6d2fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'}\n",
    "url = 'https://yandex.ru/news/'\n",
    "\n",
    "session = requests.Session()\n",
    "response = session.get(url, headers=headers)\n",
    "\n",
    "print(response.ok) \n",
    "dom_yandex = html.fromstring(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188cc6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yandex_news_scraping():\n",
    "    yandex_news = {}\n",
    "    \n",
    "    def assemble_a_dictionary(n, i, section_name, category_name, headlines, text_news, link_to_news, news_source, news_time):\n",
    "        section_name = i\n",
    "        str_news = f'{n+1} {section_name} {category_name}'\n",
    "        yandex_news[str_news] = {\n",
    "            'headlines': headlines,\n",
    "            'text_news': text_news,\n",
    "            'link_to_news': link_to_news,\n",
    "            'news_source': news_source,\n",
    "            'news_time': news_time}\n",
    "               \n",
    "    section = dom_yandex.xpath(\"//div[@class='mg-grid__col mg-grid__col_xs_12 mg-grid__col_sm_9']/section/@*\")\n",
    "    col_xs_ = [4, 8]\n",
    "    for n, i in enumerate(section):\n",
    "        for col in col_xs_:\n",
    "            section_name = None\n",
    "            if section.index(i) == 0:\n",
    "                if col == 8:                \n",
    "                    str_path = f\"//section[@aria-labelledby='{i}']/div/div[contains(@class, 'col_xs_{col}')]/div/div[2]\"\n",
    "                    headlines = ''.join(dom_yandex.xpath(f\"{str_path}/h2/a/text()\"))\n",
    "                    text_news = ''.join(dom_yandex.xpath(f\"{str_path}/div/text()\"))\n",
    "                    link_to_news = ''.join(dom_yandex.xpath(f\"{str_path}/h2/a/@href\"))\n",
    "                    news_source = ''.join(dom_yandex.xpath(f\"{str_path}/div[2]/div/div/span/a/text()\"))\n",
    "                    news_time = ''.join(dom_yandex.xpath(f\"{str_path}/div[2]/div/div/span[2]/text()\"))\n",
    "                    assemble_a_dictionary(n, i, section_name, 'general', headlines, text_news, link_to_news, news_source, news_time)\n",
    "                else:\n",
    "                    str_path = dom_yandex.xpath(f\"//section[@aria-labelledby='{i}']/div/div[contains(@class, 'col_xs_{col}')]/div\")\n",
    "                    step = 1\n",
    "                    for num in str_path:\n",
    "                        headlines = num.xpath(\"./div/div/h2/a/text()\")[0]\n",
    "                        text_news = num.xpath(\"./div/div/div[@class='mg-card__annotation']/text()\")[0]\n",
    "                        link_to_news = num.xpath(\"./div/div/h2/a/@href\")[0]\n",
    "                        news_source = num.xpath(\"./div[3]/div/div/span/a/text()\")[0]\n",
    "                        news_time = num.xpath(\"./div[3]/div/div/span[2]/text()\")[0]\n",
    "                        assemble_a_dictionary(n, i, section_name, step, headlines, text_news, link_to_news, news_source, news_time)\n",
    "                        step += 1\n",
    "            else:\n",
    "                if col == 4:\n",
    "                    str_path = dom_yandex.xpath(f\"//section[@aria-labelledby='{i}']/div[2]/div[contains(@class, 'col_xs_{col}')]/div\")\n",
    "                    step = 1\n",
    "                    for num in str_path:\n",
    "                        headlines = num.xpath(\"./div/div/h2/a/text()\")[0]\n",
    "                        text_news = num.xpath(\"./div//div/div[@class='mg-card__annotation']/text()\")[0]\n",
    "                        link_to_news = num.xpath(\"./div/div/h2/a/@href\")[0]\n",
    "                        news_source = num.xpath(\"./div[3]/div/div/span/a/text()\")[0]\n",
    "                        news_time = num.xpath(\"./div[3]/div/div/span[2]/text()\")[0]\n",
    "                        assemble_a_dictionary(n, i, section_name, 'big', headlines, text_news, link_to_news, news_source, news_time)\n",
    "                        step += 1\n",
    "                else:\n",
    "                    str_path = dom_yandex.xpath(f\"//section[@aria-labelledby='{i}']/div[2]/div[contains(@class, 'col_xs_{col}')]/div/div\")\n",
    "                    step = 1\n",
    "                    for num in str_path:\n",
    "                        headlines = num.xpath(\"./div/div/div/div/h2/a/text()\")[0]\n",
    "                        text_news = num.xpath(\"./div/div/div/div/div/text()\")[0]\n",
    "                        link_to_news = num.xpath(\"./div/div/div/div/h2/a/@href\")[0]\n",
    "                        news_source = num.xpath(\"./div/div[2]/div/div/span/a/text()\")[0]\n",
    "                        news_time = num.xpath(\"./div/div[2]/div/div/span[2]/text()\")[0]\n",
    "                        assemble_a_dictionary(n, i, section_name, step, headlines, text_news, link_to_news, news_source, news_time)\n",
    "                        step += 1  \n",
    "    with open('yandex_news.json', 'w', encoding='UTF-8') as f:\n",
    "        json.dump(yandex_news, f)\n",
    "        print('файл \"yandex_news.json\" создан!')\n",
    "    return yandex_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320a9a88",
   "metadata": {},
   "source": [
    "проверим за собой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df3cbbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "файл \"yandex_news.json\" создан!\n",
      "\n",
      "количество новостей: 65\n"
     ]
    }
   ],
   "source": [
    "yandex = yandex_news_scraping()\n",
    "print(f'\\nколичество новостей: {len(yandex)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9da618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1 top-heading 2',\n",
      " {'headlines': 'МИД России сообщил о\\xa0гибели двух сотрудников посольства '\n",
      "               'в\\xa0Афганистане в\\xa0результате теракта',\n",
      "  'link_to_news': 'https://yandex.ru/news/story/MID_Rossii_soobshhil_ogibeli_dvukh_sotrudnikov_posolstva_vAfganistane_vrezultate_terakta--b1d08d42f95d11e72d64aff14de8b062?lang=ru&rubric=index&fan=1&stid=vYrzegt-3zVIJcJC5hrs&t=1662383735&tt=true&persistent_id=221692774&story=357b5eae-af08-50c7-9802-2055ce4c95bd',\n",
      "  'news_source': 'Газета.Ru',\n",
      "  'news_time': '15:42',\n",
      "  'text_news': 'МИД России сообщил о гибели двух сотрудников посольства в '\n",
      "               'Афганистане в результате теракта, сообщается на сайте '\n",
      "               'ведомства.'})\n",
      "('13 Авто11 4',\n",
      " {'headlines': 'Автоэксперт Попов спрогнозировал возврат ушедших с\\xa0рынка РФ '\n",
      "               'автобрендов в\\xa02023 году',\n",
      "  'link_to_news': 'https://yandex.ru/news/story/Avtoehkspert_Popov_sprognoziroval_vozvrat_ushedshikh_srynka_RF_avtobrendov_v2023_godu--284791b53c482d9547362d0030fb8b19?lang=ru&rubric=auto&fan=1&stid=cCKrxEnbdxiIkUeJnAyH&t=1662383735&persistent_id=221669093&story=42d00dfc-f33f-5558-a69a-d33a311e0afc',\n",
      "  'news_source': 'CarsWeek.ru',\n",
      "  'news_time': '15:02',\n",
      "  'text_news': 'Независимый автомобильный эксперт Дмитрий Попов ждёт, что '\n",
      "               'отечественный авторынок может взять курс на восстановление в '\n",
      "               'середине 2023 года.'})\n"
     ]
    }
   ],
   "source": [
    "# выборочно посмотрим на 2 новости, чтоб увидеть вид их записи\n",
    "\n",
    "items = list(yandex.items())\n",
    "pprint(items[1])\n",
    "pprint(items[64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf031f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # если очень хочется - посмотреть все новости в блокноте можно здесь:\n",
    "# pprint(yandex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3739df",
   "metadata": {},
   "source": [
    "# 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b193f885",
   "metadata": {},
   "source": [
    "### https://lenta.ru/\n",
    "\n",
    "На Ленте новости, условно, пожно поделить на две категори, поэтому я написал функцию lenta_news_scraping(), которая принимает 2 аргумента на два типа новостей с сайта lenta.ru:\n",
    "\n",
    "1) **агумент а = новости, у которых в есть атрибут класса \"card-mini\".** Таких новостей на сайте самое большое количество, порядка 90. Они, в свою очередь, также размещаются в отдельных тематических блоках, один из которых называется \"Главные новости\". Для блока \"Главных новостей\" нет времени публикации и я его выделяю в отдельную категорию\n",
    "\n",
    "2) **аргумент b  = новости, у которых в есть атрибут класса \"card-big\".** Эти новости размазанны по всей странице, они сопровождаются картинками и своими заголовками больше напоминают бульварные жёлтые статьи, чем что-то серьёзное. Однако это тоже новости и их на сайте порядка 50-ти (в разное время суток разное количество)\n",
    "\n",
    "Функция, в зависимости от количества переданных в неё аргументов (1 ли 2) может возвращать на выбор один из типов новостей либо оба типа новостей вместе\n",
    "\n",
    "Функция возвращает словарь, с вложенным в него словарями новостей. Ключи основного словаря - это пронумерованные категории новостей. Категории такие:\n",
    "\n",
    "**новости агрумента a:**\n",
    "\n",
    "$\\;\\;\\;\\;\\;$ - **regular_news** - регулярные новости\n",
    "\n",
    "$\\;\\;\\;\\;\\;$ - **prime_news** - новости из блока \"Главные новости\"\n",
    "\n",
    "**новости агрумента b:**\n",
    "\n",
    "$\\;\\;\\;\\;\\;$ - **card_big_news** - новости \"с картинками\" на сайте\n",
    "\n",
    "$\\;\\;\\;\\;\\;$ - **новость из раздела с одним большим фото**\n",
    "\n",
    "Все категории содержат в себе:\n",
    "\n",
    "- **title** - название новости \n",
    "\n",
    "- **link** - кликабельную ссылку на неё (ссылки собирал в абсолютные, т.к. в зависимости от источника они были разными) и\n",
    "\n",
    "- **time** дату/время публикации ( формат даты/времени у каждого типа новостей разный)\n",
    "\n",
    "В итоге мы получаем JSON-структуру данных, которую записываем в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49c10a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'}\n",
    "url = 'https://lenta.ru/'\n",
    "\n",
    "session = requests.Session()\n",
    "response = session.get(url, headers=headers)\n",
    "\n",
    "print(response.ok)\n",
    "dom_lenta = html.fromstring(response.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5007022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenta_news_scraping(a=None, b=None):\n",
    "    \n",
    "    url = 'https://lenta.ru/'       \n",
    "    mini_news = dom_lenta.xpath(\"//div[@class='card-mini__text']\")\n",
    "    card_big = dom_lenta.xpath(\"//a[contains(@class, 'card-big')]\")\n",
    "    lenta_list = {}\n",
    "    \n",
    "    def filling_json(href, link, time, news_category, n, name_news):\n",
    "        for x in href:\n",
    "            if x.find('http'):\n",
    "                x = url[:-1] + x\n",
    "            link = x\n",
    "            lenta_list[f'{n+1} {news_category}'] = {\n",
    "                'title': name_news,\n",
    "                'time': time,\n",
    "                'link': link}\n",
    "\n",
    "    def regular_news():\n",
    "        for n, i in enumerate(mini_news):\n",
    "            news_category = 'regular_news'\n",
    "            link = None\n",
    "            name_news = i.xpath(\"./span[@class='card-mini__title']/text()\")[0]\n",
    "            time = ''.join(i.xpath(\"./div[@class='card-mini__info']/time/text()\"))\n",
    "            href = i.xpath(\"./../@href\")\n",
    "            if not time:\n",
    "                news_category = 'prime_news'\n",
    "            filling_json(href, link, time, news_category, n, name_news)\n",
    "\n",
    "    def card_big_news():\n",
    "        news_category = 'card_big_news'\n",
    "        for n, i in enumerate(card_big):\n",
    "            link = None\n",
    "            name_news =  ''.join(i.xpath(\"./div[2]/h3/text()\"))\n",
    "            time =  ''.join(i.xpath(\"./div[3]/time/text()\"))\n",
    "            href = i.xpath(\"./@href\")\n",
    "            filling_json(href, link, time, news_category, n, name_news)\n",
    "            \n",
    "        big_news = dom_lenta.xpath(\"//a[contains(@class, 'card-feature')]/div[2]/h3/text()\")[0]\n",
    "        big_text = ''.join(dom_lenta.xpath(\"//span[contains(@class, 'card-feature__description')]/text()\"))\n",
    "        big_href = dom_lenta.xpath(\"//a[contains(@class, 'card-feature')]/@href\")\n",
    "        big_href = url[:-1] + big_href[0]\n",
    "        lenta_list[f'1 news with photo'] = {\n",
    "                'title': big_news + big_text,\n",
    "                'time': '',\n",
    "                'link': big_href}\n",
    "    \n",
    "    if a:\n",
    "        regular_news()\n",
    "    if b:\n",
    "        card_big_news()\n",
    "        \n",
    "    with open('lenta_news.json', 'w', encoding='UTF-8') as f:\n",
    "        json.dump(lenta_list, f)\n",
    "        print('файл \"lenta_news.json\" создан!')\n",
    "        \n",
    "    return lenta_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4479e26a",
   "metadata": {},
   "source": [
    "проверим за собой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ca93501",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "файл \"lenta_news.json\" создан!\n",
      "\n",
      "количество новостей: 143\n"
     ]
    }
   ],
   "source": [
    "a, b = 1, 2\n",
    "lenta = lenta_news_scraping(a, b)\n",
    "print(f'\\nколичество новостей: {len(lenta)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31050186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1 regular_news',\n",
      " {'link': 'https://lenta.ru/news/2022/09/05/odnoklassniki/',\n",
      "  'time': '16:21',\n",
      "  'title': '«Одноклассники» запустили движение благодарностей учителям'})\n",
      "('1 news with photo',\n",
      " {'link': 'https://lenta.ru/articles/2022/09/05/liz_truss/',\n",
      "  'time': '',\n",
      "  'title': 'Железная леди — 2. Кто такая новый премьер-министр Великобритании '\n",
      "           'Лиз Трасс и почему ее не любят в России?'})\n",
      "('17 card_big_news',\n",
      " {'link': 'https://lenta.ru/articles/2022/08/29/porty1/',\n",
      "  'time': '14:37, 29 августа 2022',\n",
      "  'title': 'Разворот к морю.'})\n"
     ]
    }
   ],
   "source": [
    "# выборочно посмотрим на 3 новости, чтоб увидеть вид их записи\n",
    "\n",
    "items = list(lenta.items())\n",
    "pprint(items[0])\n",
    "pprint(items[-1])\n",
    "pprint(items[105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7093bece",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # если очень хочется - посмотреть все новости в блокноте можно здесь:\n",
    "# pprint(lenta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42825198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
