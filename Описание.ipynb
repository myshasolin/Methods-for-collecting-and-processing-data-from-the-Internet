{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292eff8f",
   "metadata": {},
   "source": [
    "## I вариант\n",
    "\n",
    "1) Доработать паука в имеющемся проекте, чтобы он формировал item по структуре:\n",
    "\n",
    "- Наименование вакансии\n",
    "- Зарплата от\n",
    "- Зарплата до\n",
    "- Ссылку на саму вакансию\n",
    "- И складывал все записи в БД(любую)\n",
    "\n",
    "2) Создать в имеющемся проекте второго паука по сбору вакансий с сайта superjob. Паук должен формировать item'ы по аналогичной структуре и складывать данные также в БД"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51846040",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "\n",
    "## Решение\n",
    "\n",
    "Для первого задания ~~дописал~~ переписал проект и теперь пауков там три – для HeadHunter, Superjob и Rabota ru\n",
    "\n",
    "Для разнообразия собираю вакансии слесарей, почему бы и нет))\n",
    "\n",
    "Собирается и обрабатывается информация:\n",
    "\n",
    "- **_id** – назначаем его сами. Это ссылка на вакансию\n",
    "- **company_name** – наименование компании (добавил эту строчку, мне кажется она нужной)\n",
    "- **vacanvies_name** – название вакансии\n",
    "- **salary** – зарплата (строчки от(тип ‘int’), до(тип ‘int’), валюта(тип ‘int’)\n",
    "- **url** – ссылка на вакансию\n",
    "\n",
    "Если _id повторяется, то мы получаем сообщение об этом и с помощью replace_one() обновляем информацию в документе\n",
    "\n",
    "Строчку зарплаты обрабатываю с помощью функции, записанной к прошлому дз, не пропадать же велосипеду, раз он так славно едет)) теперь функция – не функция, а дополнительный метод в pipeline\n",
    "\n",
    "Только для сайта **rabota.ru** дополнительно обрабатываю название вакансии и компании с помощью регулярного, так как только от них строчки приходят с переносами по краям и неприлично большим количеством отступов. Плюс отдельно для этого сайта продумал переход по страницам – с помощью конкатенации строки из недоделанной кнопки «вперёд» и недописанного url. Без них, как я понял, мой паук проваливался на страницу вакансии и не возвращался обратно, а начинал уходить по предложке вакансий внизу (что-то типа раздела \"Вам может понравиться\" в интернет-магазинах), и поэтому при поиске вакансии \"Слесарь\" через какое-то время начинало собираться всё подряд - \"Менекджер по продажам\", \"Бухгалтер-делопроизводитель\", \"Водитель погрузчика\" и т.п. Подправил, проверил, больше паук так не делает.\n",
    "\n",
    "В runner дополнительно добавил d.addBoth(lambda _: reactor.stop()) – нагуглил этот метод. Без него код в Pycharm в режиме отладки даже после полной отработки не хотел останавливаться, а с ним делает это очень даже\n",
    "\n",
    "получившиеся JSON-файлы выгрузил из MongoDB Compass, названия их - \n",
    "\n",
    "- hh_ru (1200 вакансий) \n",
    "- rabota_ru (643 вакансии)\n",
    "- superjob_ru (190 вакансий)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb5d1ef",
   "metadata": {},
   "source": [
    "## II вариант\n",
    "\n",
    "1) Создать пауков по сбору данных о книгах с сайтов labirint.ru и/или book24.ru\n",
    "\n",
    "2) Каждый паук должен собирать:\n",
    "\n",
    "- Ссылку на книгу\n",
    "- Наименование книги\n",
    "- Автор(ы)\n",
    "- Основную цену\n",
    "- Цену со скидкой\n",
    "- Рейтинг книги\n",
    "\n",
    "3) Собранная информация должна складываться в базу данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd37178",
   "metadata": {},
   "source": [
    "____________________________\n",
    "\n",
    "## Решение\n",
    "\n",
    "В книжных магазинах парсил направление «религиоведение», что-то потянуло на великое))\n",
    "\n",
    "Собирается и обрабатывается информация:\n",
    "\n",
    "- **book_title** – название книги\n",
    "- **authors_name** – автор\n",
    "- **base_price** – цена без скидки\n",
    "- **discount_price** – цена со скидкой(тип ‘float’)\n",
    "- **book_rating** – рейтинг книги(тип ‘float’)\n",
    "- **link** - ссылка на книгу\n",
    "\n",
    "1) **По Лабиринту** – оказался очень простой и интересный для парсинга сайт. Первый же вывод, который сам напрашивается при запуске паука – это то, что Лабиринт совсем не чистит свои остатки и на сайте товара вываливается больше процентов на 70 от того, что действительно есть в наличии. Я не стал дополнительно отсеивать пустые значения, так как было интересно собрать все предложения по выбранному направлению. В целом, если вообразить в дальнейшем работу с такой базой, то при необходимости всегда в готовом JSON можно отфильтровать все пустые категории, убрав те товары, у который базовая цена и цена со скидкой = 0\n",
    "\n",
    "2) **По book24** - трудный сайт, информация не цепляется как надо, кнопка \"Вперёд\" мне не поддалась. Решил так - считаю для перехода в цикле while 50 страниц (с запасом, можно сделать меньше), в f-строке меняю адрес страницы, на которую с помощью follow() перехожу. И уже на каждой странице, там, где они есть, собираю ссылки на книги, по 30 шт. со страницы. Ну и дальше всё по стандарту \n",
    "\n",
    "получившиеся JSON-файлы выгрузил из MongoDB Compass, названия их - \n",
    "\n",
    "- book24 (872 книги)\n",
    "- labirint (978 книг)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
